# December 2016

https://www.coursera.org/learn/neural-networks

## 2016/12/01

- Week7
- Equivalence between feed-forward nets and recurrent nets
- Review: backpropagation with weight constraints: compute separately and add up
- Extra issue: train 'initial states' of hidden/output units
- Toy example: binary addition
    - two input units, three fully-connected hidden units, one output
    - it learns four distinct patterns (activity vectors) corresponding to states in FSA
    - double the input: FSA -> square the states, NN -> double the hidden units
